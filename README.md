# Задание 1: Сравнение CNN и полносвязных сетей

## 1.1 Сравнение на MNIST
Обучил модели:
- Полносвязная сеть (3-4 слоя)
- Простая CNN (2-3 conv слоя)
- CNN с Residual Block

Построил графики, позволяющие сравнить Полносвязную модель и CNN. Они доступны в plots/cnn_vs_fc_comparison/compare

## Сравнение моделей

| Модель       | Время обучения (сек) | Время inference (сек) | Точность (train) | Точность (test) | Параметры |
|--------------|---------------------:|----------------------:|-----------------:|----------------:|----------:|
| FC_3layer    |              125.45  |                1.33   |           0.9932 |          0.9793 |   235,146 |
| SimpleCNN    |              132.98  |                1.72   |           0.9963 |          0.9919 |   421,642 |
| ResCNN       |              150.36  |                1.64   |           0.9964 |          0.9943 |   160,906 |


**FC_3layer** быстрее всего работает на inference (1.33 сек), но заметно уступает в точности

**SimpleCNN** — баланс между скоростью и качеством, но требует больше параметров

**ResCNN** показывает наивысшую точность на тесте (99.43%) с наименьшим числом параметров

Кривая обучения для полносвязной сети. Модель переобучилась. Loss падает на train но не на test. 

![FC_3layer_train_history](https://github.com/user-attachments/assets/26529326-3d06-4f0c-8577-a9cd492049ca)

Также кривая обучения для простой CNN. Модель не переобучилась.

![SimpleCNN_train_history](https://github.com/user-attachments/assets/0916468f-f401-4198-9509-62e04b9b4240)

Также приведу график сравнения полносвязной сети с CNN с Residual блок

![mnist_FC_3layer_vs_ResCNN](https://github.com/user-attachments/assets/a12088c8-a2d2-4856-97f5-4d63a72f34e1)

CNN оказалась гораздо лучше полносвязной модели.

## 1.2 Сравнение на CIFAR-10
Обучил модели:
- Полносвязная сеть (глубокая)
- CNN с Residual блоками
- CNN с регуляризацией и Residual блоками

## Сравнение моделей

| Модель      | Время обучения (сек) | Время inference (сек) | Точность (train) | Точность (test) | Параметры   |
|-------------|---------------------:|----------------------:|-----------------:|----------------:|------------:|
| FC_deep     |             138.21   |                1.78   |           0.6808 |          0.5414 | 9,089,610  |
| ResCNN      |             149.63   |                1.97   |           0.9037 |          0.8139 |   161,482  |
| RegResCNN   |             150.78   |                1.91   |           0.9071 |          0.7747 | 1,506,634  |

1. **FC_deep**:
   - Слишком глубокая архитектура (9M параметров)
   - Низкая точность (54.14% на тесте)

2. **ResCNN** демонстрирует лучший баланс:
   - Высокая тестовая точность (81.39%)
   - Минимальное количество параметров (161k)
   - Приемлемое время inference (1.97 сек)

3. **RegResCNN**:
   - Больше параметров чем у ResCNN, но ниже точность

Все три модели переобучились. Хуже всего у глубокой полносвязной сети:

![FC_deep_train_history](https://github.com/user-attachments/assets/98c63dd8-7522-4c6c-99b3-82377fd6fb4d)

CNN с Residual блоками:

![ResCNN_train_history](https://github.com/user-attachments/assets/b414afab-bae9-453b-9c23-3b87e16d6d11)

Также построил сравнительные графики

Пример: Полносвязная глубокая модель VS CNN с регуляризацией и Residual блоками. CNN вновь показала себя лучше

![cifar_FC_deep_vs_RegResCNN](https://github.com/user-attachments/assets/70f59552-e684-40fa-b812-c899214b799f)

Также для всех моделей построил матрицы ошибок. Приведу ее для CNN с Residual блоками. Модель неплохо предсказывает, но есть отдельные классы, где модель много ошибается

![ResCNN_confusion_matrix](https://github.com/user-attachments/assets/16456b30-ed4a-47ae-b0be-27f0879bf28f)

Также для всех моделей построил gradient flow. CNN с резуляризацией и и Residual блоками. Многие веса близки к нулю, это может говорить о том, что минимум функции где-то рядом

![RegResCNN_gradient_flow](https://github.com/user-attachments/assets/78655692-24a1-4f7a-b5e3-ec54394a5ea6)

# Задание 2: Анализ архитектур CNN

## 2.1 Влияние размера ядра свертки

Для этого задания реализовал класс AdaptiveKernelCNN, который позволил создать модели с нужными размерами ядер сверстки:

- 3x3 ядра
- 5x5 ядра
- 7x7 ядра
- Комбинация разных размеров (1x1 + 3x3)

Приведу таблицу результатов на cifar
## Сравнение свёрточных архитектур с разными ядрами

| Модель   | Параметры | Рецептивное поле | Время обучения (сек) | Время inference (сек) | Точность (train) | Точность (test) |
|----------|----------:|-----------------:|---------------------:|----------------------:|-----------------:|----------------:|
| 1x1_3x3  |   544,330 |               3  |              139.68  |                2.22   |           0.7598 |          0.6649 |
| 3x3      |   545,098 |               5  |              137.92  |                2.20   |           0.8301 |          0.7145 |
| 5x5      |   579,402 |               9  |              145.32  |                2.39   |           0.8320 |          0.7192 |
| 7x7      |   630,858 |              13  |              144.97  |                1.99   |           0.7802 |          0.7124 |

- Число рецептивных полей возрастает с увеличением размера ядер
- Лучший результат точности у **5x5** (71.92%) при самом низком времени обучения (но в целом, модели приблизительно одинаково обучались по времени)
- Гибридная **1x1_3x3** у меня показала худшую точность (66.49%)

Активация первого слоя для 3х3:

![3x3_activations](https://github.com/user-attachments/assets/96ed5b40-41f2-4a62-8add-4f90fe6c7fea)

Активация первого слоя для 7х7:

![7x7_activations](https://github.com/user-attachments/assets/d05e4a3c-2a63-43fd-98c0-fd86a7118d22)

По моим наблюдениям, чем больше размер ядра, тем более абстрактным становятся представления в слое активации. Для 3х3 четко видны контуры чисел, для 7х7 изображения больше похожи на композиции

## 2.2 Влияние глубины CNN

Для этого задания реализовал класс AdaptiveDepthCNN, который позволил создать модели с нужным числом conv слоев:

- Неглубокая CNN (2 conv слоя)
- Средняя CNN (4 conv слоя)
- Глубокая CNN (6+ conv слоев)

Также использовал CNN с Residual связями

Таблица с результатами на cifar:

## Сравнение архитектур CNN с разной глубиной

| Модель            | Параметры | Время обучения (сек) | Время inference (сек) | Точность (train) | Точность (test) |
|-------------------|----------:|---------------------:|----------------------:|-----------------:|----------------:|
| CNNWithResidual   |   161,482 |              166.52  |                2.23   |           0.9047 |          0.8214 |
| 2_conv            | 2,117,962 |              148.75  |                1.98   |           0.9399 |          0.6932 |
| 4_conv            | 2,486,986 |              170.57  |                2.27   |           0.9381 |          0.7785 |
| 6_conv            | 2,094,282 |              207.14  |                2.42   |           0.9170 |          0.7935 |

 **CNNWithResidual** показывает наивысшую тестовую точность (82.14%) при минимальном числе параметров (161k). У других моделей число параметров кратно больше.

 Чем больше conv слоев, тем дольше обучается модель

Изучил градиенты по эпохам. Приведу пример для CNNWithResidual (cifar)

эпоха 2:

![CNNWithResidual_Epoch_2](https://github.com/user-attachments/assets/0965cec6-0fb2-4f2f-a97e-5586958eaa85)

эпохе 10:

![CNNWithResidual_Epoch_10](https://github.com/user-attachments/assets/39371abc-d354-4d6b-b5fa-32842b643362)

Значения весов уменьшились

Также для всех моделей построил feature maps. Видно, как с каждым новым слоем изображения становятся все более абстрактными

![feature_map_CNNWithResidual](https://github.com/user-attachments/assets/85ab2d22-6fa3-4909-8676-f55d9f8c2e8a)

# Задание 3: Кастомные слои и эксперименты

## 3.1 Реализация кастомных слоев

реализовал требуемые слои. Проверил их корректность с помощью мини-тестов

## 3.2 Эксперименты с Residual блоками

Реализовал необходимые Residual блоки. 

Таблица результатов на cifar:

## Сравнение модификаций CNN архитектур

| Модель              | Время обучения (сек) | Точность (train) | Точность (test) | Параметры |
|---------------------|---------------------:|-----------------:|----------------:|----------:|
| CNNWithBottleneck   |              221.96  |           0.8994 |          0.7984 |   226,890 |
| CNNWithWide         |              190.03  |           0.9247 |          0.8174 |   309,258 |
| CNNWithResidual     |              163.65  |           0.9014 |          0.8208 |   161,482 |

У меня получилось так, что CNNWithBottleneck показала худшие результаты в точности при самом большом времени обучения.

Базовый Residual блок имеет наименьшее число параметров, а CNNWithWide - наибольшее

CNNWithWide обучалась стабильнее всех, а CNNWithBottleneck - нестабильнее всех.

CNNWithWide:

![CNNWithWide_train_history](https://github.com/user-attachments/assets/d212690b-381c-48bc-9629-32216726b643)

CNNWithBottleneck:

![CNNWithBottleneck_train_history](https://github.com/user-attachments/assets/94f1388d-284f-49e0-9f47-45f95982d49d)

